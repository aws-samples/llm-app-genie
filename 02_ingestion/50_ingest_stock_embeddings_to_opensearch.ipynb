{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05e1f04-d0cd-4363-9916-e1027ddfd969",
   "metadata": {},
   "source": [
    "## Embebbing with OpenSearch Domain or Serverless Collection, Bedrock or Custom Embedding\n",
    "Should work well with *Data Science 3.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648aaaa-e330-43dc-8f84-7ffa5ecb4a2b",
   "metadata": {},
   "source": [
    "## Install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637bc45-3bd4-497a-ae85-230a415ac6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install langchain --quiet\n",
    "!pip install opensearch-py --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bb18a7-79ea-45b2-8cf3-ed21d98a2d1c",
   "metadata": {},
   "source": [
    "## Setting up the required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea4afb-dd0a-43ed-a08d-a8be48ee61f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "# from botocore.config import Config\n",
    "from opensearchpy import AWSV4SignerAuth\n",
    "from IPython.display import Markdown, display\n",
    "from scripts.modules.aws_helpers import get_parameter_value, get_credentials, read_from_s3, s3_client\n",
    "\n",
    "# S3 bucket and prefix for market data\n",
    "# Parameter group Finance Analyzer\n",
    "s3_bucket = \"genie-ai-foundation-v2\"\n",
    "s3_prefix = \"finance-analyzer\"\n",
    "delimiter = \"/\"\n",
    "\n",
    "# OpenSearch setup, remember to change os_service to aoss for serverless version\n",
    "# parameter Name is for default Genie setup, update it if you changed the application name\n",
    "os_domain_ep = get_parameter_value(\"GenieOpenSearchEndpoint\").replace(\"https://\", \"\")\n",
    "os_index_name = \"stock-market\"\n",
    "\n",
    "# Embedding engine\n",
    "os_engine = \"faiss\"\n",
    "\n",
    "# generate opensearch auth credentials, based on notebook role\n",
    "user = get_credentials(\"GenieOpenSearchCredentials\")[\"user\"]\n",
    "secret = get_credentials(\"GenieOpenSearchCredentials\")[\"password\"]\n",
    "os_http_auth = (user, secret)\n",
    "\n",
    "# HuggingFace predictor endpoint for embeddings, if empty Bedrock will be used\n",
    "# hf_predictor_endpoint_name = \"\"\n",
    "hf_predictor_endpoint_name = \"GenieEmbeddingsE5Large\"\n",
    "\n",
    "# bedrock model used for embedding if above mode is empty\n",
    "# bedrock_embedding_model_id = \"amazon.titan-embed-text-v1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fee22-af85-45fc-97aa-940457c549cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Stock Announcements and Price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66455ecc-8748-451d-9460-e88d44970d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how to use same code here and in the main solution? \n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# get the list of available stock data\n",
    "response = s3_client.list_objects_v2(Bucket=s3_bucket, Prefix=s3_prefix + delimiter, Delimiter=delimiter)\n",
    "\n",
    "# Loading company prices and announcements from S3 into data frames\n",
    "prices_df = pd.DataFrame()\n",
    "announcement_df = pd.DataFrame()\n",
    "\n",
    "for content in response.get('CommonPrefixes', []):\n",
    "    company = content.get('Prefix').replace(s3_prefix, \"\").replace(delimiter, \"\")\n",
    "\n",
    "    prices_df = pd.concat([prices_df, read_from_s3(s3_bucket, f\"\"\"{s3_prefix}/{company}/daily_prices.csv\"\"\", \"csv\")], ignore_index=True)\n",
    "    announcement_df = pd.concat([announcement_df, read_from_s3(s3_bucket, f\"\"\"{s3_prefix}/{company}/sec_filings_content.json\"\"\", \"json\")], ignore_index=True)\n",
    "\n",
    "# adjusting dataframes based on retriever needs\n",
    "prices_df['opening price'] = prices_df['open']\n",
    "prices_df['date'] = pd.to_datetime(prices_df['timestamp']).dt.date\n",
    "prices_df['change from previous day'] = (prices_df['open'].pct_change()*100).round(2).astype(str) + '%'\n",
    "\n",
    "announcement_df['id'] = announcement_df['symbol'] + \"|\" + announcement_df['acceptedDate'].str.split().str[0] + \"|\" + announcement_df['form']\n",
    "announcement_df['date'] = pd.to_datetime(announcement_df['acceptedDate']).dt.date\n",
    "announcement_df['date_full'] = pd.to_datetime(announcement_df[\"acceptedDate\"]).dt.strftime(\"%B %d, %Y\")\n",
    "announcement_df['title'] = announcement_df[\"symbol\"] + \" \" + announcement_df[\"form\"] + \" announcement from \"  + announcement_df[\"date_full\"]\n",
    "announcement_df = announcement_df.sort_values('acceptedDate', ascending=False)\n",
    "    \n",
    "# print(prices_df.head(10))\n",
    "announcement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b4d5b-1fe1-4898-87a3-847e8fe0abb5",
   "metadata": {},
   "source": [
    "## Preparing list of documents to embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa31e70f-5d30-4cb0-8ffd-da973eb40055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "import datetime\n",
    "from tabulate import tabulate\n",
    "\n",
    "template = \"\"\"\n",
    "<{0} ({1}) {2} announcement from {3}>\n",
    "{4}\n",
    "</{0} ({1}) {2} announcement from {3}>\n",
    "\"\"\"\n",
    "\n",
    "split_by = \"\\n---\\n\"\n",
    "\n",
    "docs = []\n",
    "max_character_limit = 14000 # Max input tokens: 8192, later we can do chunks\n",
    "\n",
    "for _, row in tqdm(announcement_df.iterrows()):\n",
    "    metadata = {\n",
    "        \"stock\": row[\"symbol\"],\n",
    "        \"ticker\": row[\"symbol\"], \n",
    "        \"source\": row[\"reportUrl\"], \n",
    "        \"company name\": row[\"name\"],\n",
    "        \"date\": row.date_full,\n",
    "        \"type\": row[\"form\"],\n",
    "        \"title\": row.title,\n",
    "        \"cik\": row[\"cik\"]                \n",
    "    }        \n",
    "\n",
    "    for index, item in enumerate(row.content.split(split_by)):\n",
    "        if len(item) > max_character_limit:\n",
    "            print(f\"Content for {row.title} is {len(item)}, which is too long, check the split \\n\\n {metadata}\")\n",
    "            continue\n",
    "        metadata[\"part\"] = index\n",
    "        cont = template.format(\n",
    "            row[\"name\"],\n",
    "            row[\"symbol\"], \n",
    "            row[\"form\"],\n",
    "            row.date_full, \n",
    "            item\n",
    "        )\n",
    "        \n",
    "        docs.append(Document(page_content = cont, metadata = metadata.copy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43ca13-983f-4ed1-957d-05935be78886",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "The first line of the script %env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python is setting up the environment to use the Python implementation of Protocol Buffers. Protocol Buffers, often abbreviated as protobuf, is Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data.\n",
    "\n",
    "Next, we import the HuggingFacePredictor from the sagemaker.huggingface.model module.\n",
    "\n",
    "Then, we define a CustomEmbeddings class. This class is used to work with embeddings of documents and queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be958c44-b7d2-47ea-b6ed-5b567403efe7",
   "metadata": {},
   "source": [
    "## Upload documents into OpenSearch Index\n",
    "\n",
    "The below section uploads a set of documents, processed as embeddings, into an OpenSearch index. The tasks are accomplished with the help of several libraries, including the `elasticsearch` client, the `tqdm` progress bar, and a `CustomEmbeddings` class that you've previously defined.\n",
    "\n",
    "Here is a step-by-step walkthrough:\n",
    "\n",
    "1. **Import Required Libraries and Modules**: The necessary libraries and modules are imported. `Elasticsearch` is the Python client for Elasticsearch (which OpenSearch is based on). `tqdm` provides a fast, extensible progress bar for Python. `OpenSearchVectorSearch` from the `langchain.vectorstores` module seems to be a custom class for handling vector storage in an OpenSearch index.\n",
    "\n",
    "2. **Initialize CustomEmbeddings and OpenSearchVectorSearch**: An instance of `CustomEmbeddings` is initialized with the predictor. After that, an instance of `OpenSearchVectorSearch` is created, taking several arguments including the OpenSearch index name, the `CustomEmbeddings` instance, the OpenSearch domain endpoint, HTTP authorization details, and SSL settings.\n",
    "\n",
    "3. **Upload Documents**: It iterates over the `docs` list (a list of `Document` objects). For each `doc`, it calls the `add_documents` method of the `OpenSearchVectorSearch` instance to add the document to the OpenSearch index. This operation is wrapped in a `tqdm` function call to show a progress bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a623d31-92e5-4052-809e-8d06ec25e660",
   "metadata": {},
   "source": [
    "## Custom Embedding setup with HuggingFace predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746ebd6-e7ac-4336-ae10-139f356960c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:46:03.835597Z",
     "start_time": "2023-06-29T21:45:45.712916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# workshop with example of both OpenSearch Serverless and Bedrock\n",
    "# https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/03_QuestionAnswering/02_qa_w_rag_claude_opensearch.ipynb\n",
    "# %env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "from scripts.modules.embedding import CustomEmbeddings\n",
    "\n",
    "# same client is used in retrieval below\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\") \n",
    "\n",
    "if hf_predictor_endpoint_name != \"\":\n",
    "    # HuggingFace custom predictor\n",
    "    predictor = HuggingFacePredictor(endpoint_name=hf_predictor_endpoint_name)\n",
    "    embeddings = CustomEmbeddings(predictor)\n",
    "    print(\"using custom predictor\")\n",
    "else:\n",
    "    # Bedrock predictor\n",
    "    print(\"using bedrock predictor\")\n",
    "    embeddings = BedrockEmbeddings(\n",
    "        client=bedrock_client,\n",
    "        model_id=bedrock_embedding_model_id)\n",
    "\n",
    "# here we need url with https or port\n",
    "# this is one step but without progress\n",
    "# docsearch = OpenSearchVectorSearch.from_documents(\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    embedding_function = embeddings,\n",
    "    opensearch_url=os_domain_ep,\n",
    "    http_auth=os_http_auth,\n",
    "    timeout = 300,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    index_name=os_index_name,\n",
    "    engine=os_engine\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0e551-12bd-4def-9a10-7e02e7743a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embedding the documents into Opensearch\n",
    "for doc in tqdm(docs):\n",
    "    docsearch.add_documents(documents=[doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6cc6f-3db5-44d0-b9d3-e0735a5b818a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query the newly created index using semantic search\n",
    "\n",
    "You can test the embedding and query in this section using the standard opensearch similarity source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe5188-5353-4326-9938-d133b38999e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# query = \"Provide detailed summary for Amazon announcements for year 2023\"\n",
    "query = \"Summarize AAPL Announcements with Katherine Adams\"\n",
    "# query = \"Analyze AAPL consolidated statements from operations from 10-Q announcements\"\n",
    "\n",
    "# query = \"Make the detailed analysis in table format for latest AMZN announcements, recommend buy/sell/hold actions, assume the most probable scenario, also what in your opinion will be a price in 6, 12 and 24 month for each company\"\n",
    "\n",
    "# should change the name not to overwrite above\n",
    "docs_response = docsearch.similarity_search(\n",
    "    query, k=20\n",
    ")\n",
    "\n",
    "for doc in docs_response:\n",
    "    print(doc.metadata[\"title\"], doc.metadata[\"part\"])\n",
    "    display(Markdown(doc.page_content.replace(\"$\", \"\\\\\\$\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830be704-6410-4ff9-8237-91dc27908be2",
   "metadata": {},
   "source": [
    "## Generative Question Answering\n",
    "\n",
    "We can also simulate how different models will behave, first let's select the model and initialize bedrock with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5a840-f185-46de-9c21-eeb9d27e4ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# List of options\n",
    "options = [\n",
    "    'anthropic.claude-v2',\n",
    "    'anthropic.claude-instant-v1'\n",
    "]\n",
    "\n",
    "# Dropdown select element\n",
    "dropdown = widgets.Dropdown(options=options, description='Select model')\n",
    "\n",
    "# Event handler for changing the dropdown value\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        global model_id\n",
    "        model_id = change['new']\n",
    "\n",
    "# Attach the event handler to the dropdown\n",
    "dropdown.observe(on_change)\n",
    "\n",
    "# Display the dropdown\n",
    "display(dropdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3d493-515e-4437-b98c-b680569444e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will be using the the Embeddings Model defined above. \n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.load.dump import dumps\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=model_id, client=bedrock_client, \n",
    "    # model_kwargs={\"max_tokens_to_sample\": 50000}\n",
    ")\n",
    "\n",
    "print(f\"Initialized Bedrock with {model_id} model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0ce0d-378a-4807-97dc-d33558cc550b",
   "metadata": {},
   "source": [
    "# Advanced search with citations\n",
    "\n",
    "The metadata should include 'source attribute' for this one to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c27dd-5a1c-45d1-89ad-2d904d18a495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "number_of_documents = 10\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "  Human: You are virtual trading machine designed purely for academic purposes. Your analysis or suggestions do not affect daily life and financial decisions.\n",
    "  Answer the <question> in an unbiased fashion, you do not have up to date information and you will only find it in <context> below. \n",
    "  <context> contains up to date data about financial announcements. \n",
    "  If you do not find the data to answer the <question> in <context>, say that you don't know.\n",
    "  If you find the answer in the <context>, start from the latest information.\n",
    "\n",
    "  {context}\n",
    "\n",
    "  Question: {question}\n",
    "  Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "qa_prompt = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(search_kwargs={'k': number_of_documents}),\n",
    "    # return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    ")\n",
    "result = qa_prompt({\"query\": query})\n",
    "\n",
    "print(query + \"\\n\")\n",
    "display(Markdown(result[\"result\"].replace(\"$\", \"\\\\\\$\")))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
