{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72a404-aa41-4564-a973-8d21241df42d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:32:05.309600Z",
     "start_time": "2023-06-29T21:31:48.093933Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use Data Science 2.0 Image\n",
    "!pip install transformers --quiet\n",
    "!pip install langchain --quiet\n",
    "!pip install opensearch-py --quiet\n",
    "!pip install beautifulsoup4 --quiet\n",
    "!pip install elasticsearch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460d41f-394f-4d29-88ed-7315a35c7779",
   "metadata": {},
   "source": [
    "# Amazon OpenSearch Service Setup and Secret Retrieval\n",
    "This script is used to set up a client for the Amazon OpenSearch service and retrieve secret credentials using AWS Secrets Manager.\n",
    "\n",
    "- First, we import the necessary libraries\n",
    "- Next, we set up a client for the OpenSearch service\n",
    "\n",
    "**get_credentials()**\n",
    "We define a function to retrieve secret credentials from AWS Secrets Manager.\n",
    "The function uses a client for the AWS Secrets Manager to retrieve the secret value and parse it into a Python object using json.loads().\n",
    "Args:\n",
    "- secret_id: The identifier for the secret in AWS Secrets Manager.\n",
    "- region_name: The AWS region where the secret is stored.\n",
    "Returns:\n",
    "- str: The secret value\n",
    "\n",
    "\n",
    "**get_parameter_value**\n",
    "Retrieve a parameter value from AWS Systems Manager Parameter Store.\n",
    "    \n",
    "Args:\n",
    "- parameter_name (str): The name of the parameter you want to retrieve.\n",
    "- decrypt (bool): Whether to decrypt the parameter value if it's encrypted. Default is True.\n",
    "\n",
    "Returns:\n",
    "- str: The parameter value.\n",
    "\n",
    "- Finally, we set a few additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4ff3c-5750-4dc7-8011-3381541346e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import json\n",
    "from botocore.config import Config\n",
    "import time\n",
    "\n",
    "config = Config(region_name=\"eu-west-1\")\n",
    "\n",
    "# get current session and AWS Account\n",
    "session = boto3.session.Session()\n",
    "sts_client = session.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "\n",
    "def get_credentials(secret_id: str, region_name: str) -> str:\n",
    "    client = boto3.client(\"secretsmanager\", region_name=region_name)\n",
    "    response = client.get_secret_value(SecretId=secret_id)\n",
    "    secrets_value = json.loads(response[\"SecretString\"])\n",
    "    return secrets_value\n",
    "\n",
    "\n",
    "def get_parameter_value(parameter_name, decrypt=True):\n",
    "    ssm_client = boto3.client(\"ssm\", config=config)\n",
    "    response = ssm_client.get_parameter(Name=parameter_name, WithDecryption=decrypt)\n",
    "    return response[\"Parameter\"][\"Value\"]\n",
    "\n",
    "\n",
    "# getting OpenSearch credentials\n",
    "app_prefix = \"genie\"\n",
    "user = get_credentials(app_prefix + \"_opensearch_pw\", \"eu-west-1\")[\"user\"]\n",
    "secret = get_credentials(app_prefix + \"_opensearch_pw\", \"eu-west-1\")[\"password\"]\n",
    "os_http_auth = (user, secret)\n",
    "\n",
    "# get the OpenSearch domain name from parameter\n",
    "os_domain_ep = get_parameter_value(\"opensearch_endpoint\")\n",
    "os_index_name = \"admin-ch-pressreleases-de\"  # opensearch index\n",
    "\n",
    "# huggingface predictor endpoint for embeddings\n",
    "hf_predictor_endpoint_name = get_parameter_value(\"hf_predictor_endpoint_name\")\n",
    "\n",
    "# S3 bucket and path to crawler results\n",
    "s3_bucket = f\"sagemaker-gen-ai-{account_id}-{config.region_name}\"\n",
    "s3_key = \"/crawlers/admin_ch_press_releases_de.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee308063-e5d2-43ba-8f3e-767e27cb5481",
   "metadata": {},
   "source": [
    "## Read the JSON file, containing the crawler result into data frame\n",
    "\n",
    "We can also see some pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b9dfe-5c25-49a0-bff5-5d11b898bc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:45:22.899220Z",
     "start_time": "2023-06-29T21:45:17.454014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"s3://\" + s3_bucket + s3_key)\n",
    "\n",
    "# read the crawled pages as dataframe\n",
    "df = pd.read_json(\"s3://\" + s3_bucket + s3_key)\n",
    "df.style.set_properties(**{\"text-align\": \"left\"})\n",
    "# df.head()\n",
    "\n",
    "# Display the content of 1 document\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# show example html content\n",
    "display(HTML(df.content.values[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1ede8a-dafb-49bf-8d7c-01b8765c9e34",
   "metadata": {},
   "source": [
    "## Split the documents by H html tag\n",
    "\n",
    "This section is processiing HTML content from a DataFrame (`df`), extract sections, and paragraphs from these sections, and then save the processed DataFrame to a JSON file. The details are as follows:\n",
    "\n",
    "1. **Import Required Libraries**: BeautifulSoup and SoupStrainer from the `bs4` module and the `re` (regular expressions) module are imported.\n",
    "\n",
    "2. **Define Function to Convert Paragraphs**: A function `convert_paragraphs` is defined, which takes a DataFrame row as an argument. The function extracts the HTML content and plain text content from the row, and then uses BeautifulSoup to parse the HTML. It creates a list of sections by finding all HTML headings (tags from h1 to h6). It then slices the plain text content into paragraphs based on the positions of these section headings. Paragraphs are then cleaned up (leading and trailing spaces are removed), and empty paragraphs are discarded. The function returns a list of clean paragraphs.\n",
    "\n",
    "3. **Apply Function to DataFrame**: The `convert_paragraphs` function is applied to every row in the DataFrame. The result (a Series of lists of paragraphs) is then converted to a list and stored back into a new column \"paragraphs\" in the DataFrame.\n",
    "\n",
    "4. **Store DataFrame**: The DataFrame is then saved to a JSON file named \"pages_with_paragraphs_clean_by_section.json\".\n",
    "\n",
    "5. **Generate SKU DataFrame**: A new DataFrame `df_skus` is created from the \"title\" and \"paragraphs\" columns of the original DataFrame. The `explode` function is used to transform each element of a list-like to a row, replicating the index values. The resulting DataFrame, where each paragraph has its own row with the corresponding title, is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29817138-82aa-478b-93e7-da1856a7ca61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:45:23.628670Z",
     "start_time": "2023-06-29T21:45:23.236779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import re\n",
    "\n",
    "\n",
    "def convert_paragraphs(row):\n",
    "    html = row[\"content\"]\n",
    "    textContent = row[\"textContent\"]\n",
    "    soup = BeautifulSoup(html)\n",
    "    sections = [h.text for h in soup.find_all(re.compile(\"^h[1-6]$\"))]\n",
    "    paragraphs = []\n",
    "    pos = 0\n",
    "    for section in sections:\n",
    "        split_pos = textContent.find(section, pos, len(textContent))\n",
    "        paragraphs.append(textContent[pos:split_pos])\n",
    "        pos = split_pos\n",
    "    paragraphs.append(textContent[pos : len(textContent)])\n",
    "\n",
    "    paragraphs_clean = [p.strip() for p in paragraphs if len(p.strip()) > 0]\n",
    "    return paragraphs_clean\n",
    "\n",
    "\n",
    "paragraphs = df.apply(convert_paragraphs, axis=1)\n",
    "df[\"paragraphs\"] = paragraphs.tolist()\n",
    "\n",
    "# store df to json file for later analysis\n",
    "# df.to_json(\"pages_with_paragraphs_clean_by_section.json\")\n",
    "df.to_json(\"s3://\" + s3_bucket + s3_key.replace(\".json\", \"_paragraphs.json\"))\n",
    "\n",
    "df_skus = df[[\"title\", \"paragraphs\"]].explode(\"paragraphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3111645b-61d0-4604-8abf-1b481bc33c0b",
   "metadata": {},
   "source": [
    "## Setting up the Environment\n",
    "\n",
    "The first line of the script %env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python is setting up the environment to use the Python implementation of Protocol Buffers. Protocol Buffers, often abbreviated as protobuf, is Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data.\n",
    "\n",
    "Next, we import the HuggingFacePredictor from the sagemaker.huggingface.model module.\n",
    "\n",
    "Then, we define a CustomEmbeddings class. This class is used to work with embeddings of documents and queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55349e79-48ae-41a4-a317-674b31a98c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "from sagemaker.huggingface.model import HuggingFacePredictor\n",
    "\n",
    "predictor = HuggingFacePredictor(endpoint_name=hf_predictor_endpoint_name)\n",
    "\n",
    "\n",
    "class CustomEmbeddings:\n",
    "    def __init__(self, embeddings_predictor):\n",
    "        self.embeddings_predictor = embeddings_predictor\n",
    "\n",
    "    def embed_documents(self, input_texts):\n",
    "        return self._embed_docs(input_texts, False)\n",
    "\n",
    "    def embed_query(self, query_text):\n",
    "        return self._embed_docs([query_text])[0]\n",
    "\n",
    "    def _embed_docs(self, texts, isQuery=False):\n",
    "        data = {\n",
    "            \"texts\": texts,\n",
    "        }\n",
    "\n",
    "        res = self.embeddings_predictor.predict(data=data)\n",
    "        return res[\"vectors\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce70727-383e-4fc3-9b9d-8709c676fe5e",
   "metadata": {},
   "source": [
    "## Creating a list of Document objects\n",
    "\n",
    "This code creating a list of Document objects using the data from a DataFrame (df) with splitted website documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a125c938",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:44:35.184109Z",
     "start_time": "2023-06-29T21:44:35.178896Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = []\n",
    "for index, row in df.iterrows():\n",
    "    for par_num, paragraph in enumerate(row[\"paragraphs\"]):\n",
    "        meta = {\"source\": row[\"source\"], \"title\": row[\"title\"]}\n",
    "        doc = Document(page_content=paragraph, metadata=meta)\n",
    "        docs.append(doc)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ed211-6c02-4217-b4d3-3ea391c01c72",
   "metadata": {},
   "source": [
    "## Uploade documents into OpenSearch Index\n",
    "\n",
    "The below section uploads a set of documents, processed as embeddings, into an OpenSearch index. The tasks are accomplished with the help of several libraries, including the `elasticsearch` client, the `tqdm` progress bar, and a `CustomEmbeddings` class that you've previously defined.\n",
    "\n",
    "Here is a step-by-step walkthrough:\n",
    "\n",
    "1. **Import Required Libraries and Modules**: The necessary libraries and modules are imported. `Elasticsearch` is the Python client for Elasticsearch (which OpenSearch is based on). `tqdm` provides a fast, extensible progress bar for Python. `OpenSearchVectorSearch` from the `langchain.vectorstores` module seems to be a custom class for handling vector storage in an OpenSearch index.\n",
    "\n",
    "2. **Initialize CustomEmbeddings and OpenSearchVectorSearch**: An instance of `CustomEmbeddings` is initialized with the predictor. After that, an instance of `OpenSearchVectorSearch` is created, taking several arguments including the OpenSearch index name, the `CustomEmbeddings` instance, the OpenSearch domain endpoint, HTTP authorization details, and SSL settings.\n",
    "\n",
    "3. **Upload Documents**: It iterates over the `docs` list (a list of `Document` objects). For each `doc`, it calls the `add_documents` method of the `OpenSearchVectorSearch` instance to add the document to the OpenSearch index. This operation is wrapped in a `tqdm` function call to show a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26787210-9ae4-40e3-bab5-1795b78b1282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-29T21:46:03.835597Z",
     "start_time": "2023-06-29T21:45:45.712916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looks like only langchain is required\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "from tqdm import tqdm\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "custom_embeddings = CustomEmbeddings(predictor)\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    index_name=os_index_name,\n",
    "    embedding_function=custom_embeddings,\n",
    "    opensearch_url=os_domain_ep,\n",
    "    http_auth=os_http_auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=False,\n",
    "    ssl_assert_hostname=False,\n",
    "    ssl_show_warn=False,\n",
    ")\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544c367-70f6-42ce-a496-fc2ba7292316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding document to open search index with progress bar\n",
    "for doc in tqdm(docs):\n",
    "    docsearch.add_documents(documents=[doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd1e78-070a-4723-807b-83c602a66d22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Query the newly created index\n",
    "\n",
    "You can test the embedding and query in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7489191-9473-4ac8-ba63-70d7cf7a8828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"When Digital Vignette is available?\"\n",
    "\n",
    "# should change the name not to overwrite above\n",
    "docs_response = docsearch.similarity_search(\n",
    "    q, k=10\n",
    ")  # , search_type=\"script_scoring\", space_type=\"cosinesimil\"\n",
    "\n",
    "df_res = pd.DataFrame(\n",
    "    [\n",
    "        {\"page_content\": doc.page_content, \"metadata\": doc.metadata}\n",
    "        for doc in docs_response\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_res2 = df_res.join(pd.json_normalize(df_res.metadata))\n",
    "df_res2.drop(\"metadata\", axis=1, inplace=True)\n",
    "df_res2.page_content[0]"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
